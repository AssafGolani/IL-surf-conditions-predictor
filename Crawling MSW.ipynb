{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe592ab",
   "metadata": {},
   "source": [
    "## Data Acquisition - Crawling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae25a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re for reges\n",
    "import re\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Import webdriver to initialise a browser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7feaa2",
   "metadata": {},
   "source": [
    "### definning functions to generate start and end dates of months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc56ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code ref: https://stackoverflow.com/a/13565185/8703160\n",
    "def end_of_month(any_day):\n",
    "    # this will never fail\n",
    "    # get close to the end of the month for any day, and add 4 days 'over'\n",
    "    next_month = any_day.replace(day=28) + datetime.timedelta(days=4)\n",
    "    # subtract the number of remaining 'overage' days to get last day of current month, or said programattically said, the previous day of the first of next month\n",
    "    return next_month - datetime.timedelta(days=next_month.day)\n",
    "\n",
    "def end_date_of_month_gen():\n",
    "    end_arr = []\n",
    "    for month in range(1, 13):\n",
    "        for year in range (2020, 2022):\n",
    "            end_date = (end_of_month(datetime.date(year, month, 1)))\n",
    "            end_arr.append(str(end_date))\n",
    "    return end_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d822e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_day_of_month():\n",
    "    start_arr = []\n",
    "    for month in range (1,13):\n",
    "        for year in range(2020,2022):\n",
    "            start_day_of_month = datetime.date(year, month, 1)\n",
    "            start_arr.append(str(start_day_of_month))\n",
    "    return start_arr\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f843bb77",
   "metadata": {},
   "source": [
    "### Login function with selenium for the MSW website using my credentials, I have deleted the email and password for privacy and security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1718d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#login\n",
    "def login(self):\n",
    "    email = self.find_element(By.NAME, 'email')\n",
    "    password = self.find_element(By.NAME, 'password')\n",
    "    email.send_keys(\"\")\n",
    "    password.send_keys(\"\")\n",
    "    self.find_element(By.ID,\"msw-js-login\").click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a2ed21",
   "metadata": {},
   "source": [
    "### Start web driver session  with selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703de05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 97.0.4692\n",
      "Get LATEST chromedriver version for 97.0.4692 google-chrome\n",
      "Driver [C:\\Users\\Assaf\\.wdm\\drivers\\chromedriver\\win32\\97.0.4692.71\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "baseUrl = \"https://magicseaweed.com/account/login/?dest=%2FRishon-Lezion-Surf-Report%2F3976%2FHistoric%2F%3Fstart%3D2020-01-01%26end%3D2020-01-05\"\n",
    "# Initialize webdriver and put the path where download the driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "# Launch Chrome and pass the url\n",
    "driver.get(baseUrl)\n",
    "login(driver)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6d453e",
   "metadata": {},
   "source": [
    "### store the dates in arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86fea9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-01-01', '2021-01-01', '2020-02-01', '2021-02-01', '2020-03-01', '2021-03-01', '2020-04-01', '2021-04-01', '2020-05-01', '2021-05-01', '2020-06-01', '2021-06-01', '2020-07-01', '2021-07-01', '2020-08-01', '2021-08-01', '2020-09-01', '2021-09-01', '2020-10-01', '2021-10-01', '2020-11-01', '2021-11-01', '2020-12-01', '2021-12-01']\n",
      "['2020-01-31', '2021-01-31', '2020-02-29', '2021-02-28', '2020-03-31', '2021-03-31', '2020-04-30', '2021-04-30', '2020-05-31', '2021-05-31', '2020-06-30', '2021-06-30', '2020-07-31', '2021-07-31', '2020-08-31', '2021-08-31', '2020-09-30', '2021-09-30', '2020-10-31', '2021-10-31', '2020-11-30', '2021-11-30', '2020-12-31', '2021-12-31']\n"
     ]
    }
   ],
   "source": [
    "start_date = start_day_of_month()\n",
    "print(start_date)\n",
    "end_date = end_date_of_month_gen()\n",
    "print(end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e33e8f",
   "metadata": {},
   "source": [
    "### definning the scraping data function using crawling with beautiful-soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d86c3bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(soup):\n",
    "    date = []\n",
    "    # hours = ['00:00', '03:00', '06:00', '09:00', '12:00', '15:00', '18:00','21:00']\n",
    "    hours = []\n",
    "    primarySwellHeight = []\n",
    "    primarySwellPeriod = []\n",
    "    secondarySwellHeight = []\n",
    "    secondarySwellPeriod = []\n",
    "    swellRating = []\n",
    "\n",
    "    table  = soup.find('table', {'class':'table table-primary table-forecast allSwellsActive msw-js-table msw-units-large'})\n",
    "    for tbody in table.find_all('tbody'):\n",
    "        for tr in tbody.find_all('tr'):\n",
    "            if tr.has_attr('data-timestamp'):\n",
    "                date.append(time.strftime('%Y-%m-%d %H:%M', time.localtime(int(tr['data-timestamp']))))\n",
    "            for td_time in tr.find_all('td', {'class':'nopadding-left row-title background-clear msw-js-tooltip'}):\n",
    "                hours.append(td_time.find('small').get_text().strip())\n",
    "\n",
    "                \n",
    "            for i, td_swellHeight in enumerate(tr.find_all('td', {'class':['text-center background-gray-lighter','text-center background-gray-lightest']})):\n",
    "                if i % 2 == 0:    \n",
    "                    for h4_info in td_swellHeight.find_all('h4'):\n",
    "                        primarySwellHeight.append(h4_info.text.strip())\n",
    "                elif i % 2 != 0:\n",
    "                    for h4_info in td_swellHeight.find_all('h4'):\n",
    "                        primarySwellPeriod.append(h4_info.text.strip())\n",
    "                else:\n",
    "                    continue\n",
    "                        \n",
    "\n",
    "            count = 0\n",
    "            for td_rate in tr.find_all('ul'):\n",
    "                count = len(td_rate.find_all('li', {'class':'active'}))\n",
    "                swellRating.append(count)\n",
    "    return pd.DataFrame({'date': pd.Series(date),'hour': pd.Series(hours), 'swell_rating': pd.Series(swellRating), 'primary_swell_height': pd.Series(primarySwellHeight), 'primary_swell_period': pd.Series(primarySwellPeriod)})\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d95a30",
   "metadata": {},
   "source": [
    "### here we iteratively insert the start date and end date in the url so the url will change for each month and send it to the scape data function to get all the data that we need we store all the scraped data in list L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "472329c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_res_for_url(start, end):\n",
    "    r = []\n",
    "    dynamicUrl = [\"https://www.magicseaweed.com/Rishon-Lezion-Surf-Report/3976/Historic/\", \"https://www.magicseaweed.com/Bat-Yam-Surf-Report/3662/Historic/\", \"https://www.magicseaweed.com/Hilton-Surf-Report/3658/Historic/\"]\n",
    "    for url in dynamicUrl:\n",
    "        url += \"?start=\" + start + \"&amp;end=\" + end + \"&end=\" + end\n",
    "        driver.get(url)    \n",
    "        r.append(driver.page_source)\n",
    "    return r\n",
    "\n",
    "L = []\n",
    "\n",
    "for i,j in zip(start_date, end_date):\n",
    "    html = get_res_for_url(i,j)\n",
    "    for h in html:\n",
    "        soup = BeautifulSoup(h, \"html.parser\")\n",
    "        time.sleep(3)\n",
    "        L.append(scrape_data(soup))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b249e",
   "metadata": {},
   "source": [
    "### I merged the data in L using concat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908cef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(L, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b65de3",
   "metadata": {},
   "source": [
    "### save the dataframe as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d6c1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75f2c4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>swell_rating</th>\n",
       "      <th>primary_swell_height</th>\n",
       "      <th>primary_swell_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 02:00</td>\n",
       "      <td>12am</td>\n",
       "      <td>1</td>\n",
       "      <td>1m</td>\n",
       "      <td>8s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 05:00</td>\n",
       "      <td>3am</td>\n",
       "      <td>0</td>\n",
       "      <td>1m</td>\n",
       "      <td>7s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 08:00</td>\n",
       "      <td>6am</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9m</td>\n",
       "      <td>7s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 11:00</td>\n",
       "      <td>9am</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8m</td>\n",
       "      <td>7s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 14:00</td>\n",
       "      <td>12pm</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8m</td>\n",
       "      <td>7s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17538</th>\n",
       "      <td>2021-12-31 09:00</td>\n",
       "      <td>9am</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1m</td>\n",
       "      <td>7s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17539</th>\n",
       "      <td>2021-12-31 12:00</td>\n",
       "      <td>12pm</td>\n",
       "      <td>1</td>\n",
       "      <td>1m</td>\n",
       "      <td>8s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17540</th>\n",
       "      <td>2021-12-31 15:00</td>\n",
       "      <td>3pm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9m</td>\n",
       "      <td>8s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17541</th>\n",
       "      <td>2021-12-31 18:00</td>\n",
       "      <td>6pm</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9m</td>\n",
       "      <td>8s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17542</th>\n",
       "      <td>2021-12-31 21:00</td>\n",
       "      <td>9pm</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8m</td>\n",
       "      <td>8s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17543 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   date  hour  swell_rating primary_swell_height  \\\n",
       "0      2020-01-01 02:00  12am             1                   1m   \n",
       "1      2020-01-01 05:00   3am             0                   1m   \n",
       "2      2020-01-01 08:00   6am             1                 0.9m   \n",
       "3      2020-01-01 11:00   9am             1                 0.8m   \n",
       "4      2020-01-01 14:00  12pm             0                 0.8m   \n",
       "...                 ...   ...           ...                  ...   \n",
       "17538  2021-12-31 09:00   9am             1                 1.1m   \n",
       "17539  2021-12-31 12:00  12pm             1                   1m   \n",
       "17540  2021-12-31 15:00   3pm             1                 0.9m   \n",
       "17541  2021-12-31 18:00   6pm             1                 0.9m   \n",
       "17542  2021-12-31 21:00   9pm             0                 0.8m   \n",
       "\n",
       "      primary_swell_period  \n",
       "0                       8s  \n",
       "1                       7s  \n",
       "2                       7s  \n",
       "3                       7s  \n",
       "4                       7s  \n",
       "...                    ...  \n",
       "17538                   7s  \n",
       "17539                   8s  \n",
       "17540                   8s  \n",
       "17541                   8s  \n",
       "17542                   8s  \n",
       "\n",
       "[17543 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6969aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
